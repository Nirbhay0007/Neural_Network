{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "713baf06",
   "metadata": {},
   "source": [
    "# Creating the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996fbb50",
   "metadata": {},
   "source": [
    "## Case 1 : When the class is in numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd6cce30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS IS THE negative_log [0.35667494393873245, 0.6931471805599453, 0.916290731874155]\n",
      " THIS IS THE average_loss 0.6553709521242777\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "softmax_output=[\n",
    "    0.7  0.1  0.2;\n",
    "    0.1  0.5  0.4;\n",
    "    0.3  0.4  0.3\n",
    "]\n",
    "#julia uses indexing form 1\n",
    "class_targets=[1,2,2]\n",
    "\n",
    "#Extracting the predicted probability of the correct class\n",
    "correct_probs = [softmax_output[i, class_targets[i]] for i in 1:length(class_targets)]\n",
    "negative_log=-log.(correct_probs)\n",
    "average_loss=mean(negative_log)\n",
    "println(\"THIS IS THE negative_log $negative_log\")\n",
    "println(\" THIS IS THE average_loss $average_loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d3a36",
   "metadata": {},
   "source": [
    "## Case 2: When the class target is one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf09098c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Output:\n",
      "[0.7 0.0 0.0; 0.0 0.8 0.0; 0.0 0.0 0.6]\n",
      "\n",
      "Loss per sample:\n",
      "[0.7; 0.8; 0.6;;]\n",
      "Average Loss:\n",
      "0.3635480396729776\n"
     ]
    }
   ],
   "source": [
    "# Define one-hot encoded class targets and predicted probabilities\n",
    "class_target = [1 0 0; 0 1 0; 0 0 1]  # Matrix{Int}\n",
    "prediction = [0.7 0.2 0.1; 0.1 0.8 0.1; 0.2 0.2 0.6]  # Matrix{Float64}\n",
    "\n",
    "# Element-wise multiplication (Hadamard product)\n",
    "softmax_output = class_target .* prediction\n",
    "println(\"Softmax Output:\")\n",
    "println(softmax_output)\n",
    "println()\n",
    "\n",
    "# Sum across rows to get predicted probability for correct class\n",
    "loss = sum(softmax_output, dims=2)\n",
    "println(\"Loss per sample:\")\n",
    "println(loss)\n",
    "\n",
    "# Compute negative log loss\n",
    "actual_loss = -log.(loss)\n",
    "average_loss = mean(actual_loss)\n",
    "println(\"Average Loss:\")\n",
    "println(average_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
